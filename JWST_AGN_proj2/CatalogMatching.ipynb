{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "#   1. open tphot, egs_candles, and egs_merged to read\n",
    "#   2. match RA and DEC between egs_merged and tphot\n",
    "#   3. get ID from egs_merged for matches (#2) and match to egs_candles\n",
    "#   4. make catalog with all data\n",
    "#   5. make catalog with only specific columns \n",
    "\n",
    "# note: there may be 2 matches in #2, make note of these sources. We will have to match by eye. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## imports\n",
    "# astronomy\n",
    "from astropy.io import fits\n",
    "from astropy.io import ascii\n",
    "from astropy.table import Table\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "# data \n",
    "import numpy as np\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths \n",
    "path_catalogs = 'C:\\\\Users\\\\polar\\\\OneDrive - The University of Kansas\\\\AGNerds\\\\Catalogs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open tphot\n",
    "tphot_data = ascii.read(path_catalogs+'\\\\tphot.cat')\n",
    "tphot_cols = tphot_data.colnames\n",
    "\n",
    "# show table\n",
    "# tphot_data.show_in_notebook()\n",
    "# print(tphot_cols)\n",
    "\n",
    "# important columns:\n",
    "# name = 'ra'\n",
    "# name = 'dec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open egs_merged \n",
    "egs_merged_data = Table.read(path_catalogs+'\\\\egs_merged_v1.1.fits')\n",
    "egs_merged_cols = egs_merged_data.columns\n",
    "\n",
    "# print all columns\n",
    "# for col in egs_merged_cols:\n",
    "#     print(col)\n",
    "\n",
    "# important columns:\n",
    "# name = 'ID'; format = 'K'\n",
    "# name = 'RA'; format = 'D'; unit = 'deg'\n",
    "# name = 'DEC'; format = 'D'; unit = 'deg'\n",
    "# name = 'z_best'; format = 'D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open egs_candels \n",
    "egs_candels_data_bySrc = np.genfromtxt(path_catalogs+'\\\\egs_candels_checkage_official.ir_fitting')\n",
    "egs_candels_data_byCol = egs_candels_data_bySrc.T # transpose \n",
    "# manually type column names\n",
    "egs_candels_cols = ['Source','z','L(8-1000)','er','L(3-1100)','er','L1_1','L1_2','L1_3','L1_4','L2_1','L2_2','L2_3','L2_4','L_008','er',\n",
    "                    'L_012','er','L_015','er','L_024','er','SFR_TIR','er','SFR_008','er','SFR_012','er','SFR_015','er','SFR_024','er',\n",
    "                    'SFRonly24','SFR_R+09','SFR_R+13','SFR_E+11','er','SFR_W+11','SFR1600','SFR2800','UV_beta','A(V)','SFR1600c',\n",
    "                    'SFR2800c','A(V)e','SFR1600ce','SFR2800ce','qPAH_DL+07','Umin_DL+07','gamma_DL+07','Mdust_DL+07','temp_1','temp_2',\n",
    "                    'temp_3','temp_4','temp_only24','factor_1','factor_2','factor_3','factor_4','factor_only24','F(24)','R+09_valA',\n",
    "                    'R+09_valB','R+13_valA','R+13_valB','W+11_val','l_IRAC_58','f_IRAC_58','l_IRAC_80','f_IRAC_80','l_MIPS24','f_MIPS24',\n",
    "                    'l_MIPS70','f_MIPS70','l_PACS_100','f_PACS_100','l_PACS_160','f_PACS_160','l_SPIRE_250','f_SPIRE_250','l_SPIRE_350',\n",
    "                    'f_SPIRE_350','l_SPIRE_500','f_SPIRE_500','plot_maxy','Nfit','Nobs']\n",
    "\n",
    "# important columns (access by index)\n",
    "EGSCAN_SOURCE = 0 # Source    1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Match RA and DEC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get RA and DEC from catalogs\n",
    "\n",
    "# get RA and DEC from tphot and make array\n",
    "tphot_RA  = np.array(tphot_data['ra'])\n",
    "tphot_DEC = np.array(tphot_data['dec'])\n",
    "# get RA and DEC from egs_merged (already an array)\n",
    "egs_merged_RA  = np.array(egs_merged_data['RA'])\n",
    "egs_merged_DEC = np.array(egs_merged_data['DEC'])\n",
    "\n",
    "# get coordinants \n",
    "tphot_coord = SkyCoord(ra=tphot_RA*u.deg, dec=tphot_DEC*u.deg)\n",
    "egs_merged_coord = SkyCoord(ra=egs_merged_RA*u.deg, dec=egs_merged_DEC*u.deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tphot sources:\t 1734\n",
      "Number of egs_merged sources:\t 41457\n"
     ]
    }
   ],
   "source": [
    "print('Number of tphot sources:\\t', len(tphot_RA))\n",
    "print('Number of egs_merged sources:\\t', len(egs_merged_RA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches:\t 1661\n",
      "Number of matches:\t 1661\n"
     ]
    }
   ],
   "source": [
    "## match RA and DEC between catalogs\n",
    "# DOC: https://docs.astropy.org/en/stable/coordinates/matchsep.html\n",
    "\n",
    "# idx are indices into catalog that are the closest objects to each of the coordinates in c, \n",
    "# d2d are the on-sky distances between them, and \n",
    "# d3d are the 3-dimensional distances. \n",
    "idx, d2d, d3d = egs_merged_coord.match_to_catalog_sky(tphot_coord) # idx, d2d, d3d = c.match_to_catalog_sky(catalog)\n",
    "\n",
    "# separation constraint\n",
    "max_sep = 1.0 * u.arcsec\n",
    "# max_sep = 0.5 * u.arcsec\n",
    "sep_constraint = d2d < max_sep  # use on 'c' (egs_merged_coord)\n",
    "idx_sep = idx[sep_constraint]   # use on 'catalog' (tphot)\n",
    "\n",
    "# get matches\n",
    "egs_merged_coord_matches = egs_merged_coord[sep_constraint]\n",
    "tphot_coord_matches = tphot_coord[idx_sep]\n",
    "\n",
    "# print length  \n",
    "print('Number of matches:\\t', len(egs_merged_coord_matches))\n",
    "print('Number of matches:\\t', len(tphot_coord_matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (215.054167, 52.89869738)>\n",
      "<SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (215.054131, 52.89869)>\n"
     ]
    }
   ],
   "source": [
    "# test match\n",
    "i=12\n",
    "print(egs_merged_coord_matches[i])\n",
    "print(tphot_coord_matches[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Find Duplicate Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make test list \n",
    "# testlist = np.array([3,1,2,3,3,3,4,4])\n",
    "# print(testlist)\n",
    "\n",
    "# # make mask of unique soruces \n",
    "# maskt = np.zeros(len(testlist), dtype=bool)\n",
    "# maskt[np.unique(testlist, return_index=True)[1]] = True\n",
    "\n",
    "# # get value of duplicates \n",
    "# duptestlist = np.unique(testlist[~maskt])\n",
    "# # print(duptestlist)\n",
    "\n",
    "# # set all non-unique sources to False \n",
    "# for dup in duptestlist :\n",
    "#     inst = np.where(testlist == dup)\n",
    "#     maskt[inst] = False\n",
    "\n",
    "# # remove duplicates\n",
    "# uniquetestlist = testlist[maskt]\n",
    "# print(uniquetestlist)\n",
    "\n",
    "# # show duplicates\n",
    "# duplicatetestlist = testlist[~maskt]\n",
    "# print(duplicatetestlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique:\t 1606\n",
      "Number of duplicates:\t 55\n",
      "Duplicate sources:\n",
      " [1412 1412 1427 1427 1397 1273 1273  801  660  930  930 1389 1389  970\n",
      "  127  791  791 1279  983  771  771  942  942  973  719 1106  789 1106\n",
      " 1092 1204 1204 1140 1075   38   38   34   34 1427 1397  801  660  379\n",
      "  379  970  127 1279  983  973  719  789 1092 1140 1075 1058 1058]\n"
     ]
    }
   ],
   "source": [
    "# make mask of unique soruces \n",
    "mask = np.zeros(len(idx_sep), dtype=bool)\n",
    "mask[np.unique(idx_sep, return_index=True)[1]] = True\n",
    "\n",
    "# get value of duplicates sources \n",
    "duplicates = np.unique(idx_sep[~mask])\n",
    "\n",
    "# set all non-unique sources to False \n",
    "for dup in duplicates :\n",
    "    mask[np.where(idx_sep == dup)] = False\n",
    "\n",
    "# apply mask to get unique and duplicate sources\n",
    "idx_sep_unique = idx_sep[mask]\n",
    "idx_sep_duplicates = idx_sep[~mask]\n",
    "\n",
    "# print info\n",
    "print('Number of unique:\\t', len(idx_sep_unique))\n",
    "print('Number of duplicates:\\t', len(idx_sep_duplicates))\n",
    "print('Duplicate sources:\\n', idx_sep_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique:\t 1606\n",
      "Number of duplicates:\t 55\n",
      "Duplicates:\n",
      " [ 8145  8213  9083  9116  9891 12029 12149 12519 12723 12730 12833 12999\n",
      " 13046 13688 13808 14663 14683 15291 15985 16409 16454 16515 16528 16710\n",
      " 18318 19018 19058 19070 19224 19521 19596 19795 19911 20003 20122 20378\n",
      " 20393 34656 34858 35649 35703 35878 35903 35988 36045 36528 36661 36920\n",
      " 37360 37593 37680 37791 37879 38123 38129]\n"
     ]
    }
   ],
   "source": [
    "# apply mask to egs sources\n",
    "egs_merged_i    = np.where(sep_constraint)[0]\n",
    "egs_merged_i_unique = egs_merged_i[mask]\n",
    "egs_merged_i_duplicates = egs_merged_i[~mask]\n",
    "\n",
    "# print info\n",
    "print('Number of unique:\\t', len(egs_merged_i_unique))\n",
    "print('Number of duplicates:\\t', len(egs_merged_i_duplicates))\n",
    "print('Duplicates:\\n', egs_merged_i_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (215.06161456, 52.90150667)>\n",
      "<SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (215.061606, 52.901508)>\n"
     ]
    }
   ],
   "source": [
    "# get values \n",
    "egs_merged_coord_unique = egs_merged_coord[egs_merged_i_unique]\n",
    "tphot_coord_unique = tphot_coord[idx_sep_unique]\n",
    "\n",
    "# test match\n",
    "i=1\n",
    "print(egs_merged_coord_unique[i])\n",
    "print(tphot_coord_unique[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (215.01528726, 52.91275212)>\n",
      "<SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (215.015239, 52.912741)>\n"
     ]
    }
   ],
   "source": [
    "# get values \n",
    "egs_merged_coord_duplicates = egs_merged_coord[egs_merged_i_duplicates]\n",
    "tphot_coord_duplicates = tphot_coord[idx_sep_duplicates]\n",
    "\n",
    "# test match\n",
    "i=3\n",
    "print(egs_merged_coord_duplicates[i])\n",
    "print(tphot_coord_duplicates[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Match ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get IDs\n",
    "egs_merged_ID = egs_merged_data['ID']\n",
    "egs_merged_ID_tphotMatches = egs_merged_ID[egs_merged_i_unique]\n",
    "egs_candels_ID = egs_candels_data_byCol[EGSCAN_SOURCE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to match by id (code from Connor Auge)\n",
    "def match(a, b):\n",
    "    b_set = set(b)\n",
    "    b_match = [i for i, v in enumerate(a) if v in b_set]\n",
    "    a_set = set(a)\n",
    "    a_match = [i for i, v in enumerate(b) if v in a_set]\n",
    "    a_match = np.asarray(a_match)\n",
    "    b_match = np.asarray(b_match)\n",
    "    a_match2 = np.argsort(a[b_match])\n",
    "    b_match2 = np.argsort(b[a_match])\n",
    "    return b_match[a_match2],a_match[b_match2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match \n",
    "key_merged, key_candels = match(egs_merged_ID_tphotMatches, egs_candels_ID)\n",
    "\n",
    "# apply match key\n",
    "egs_merged_ID_tphotMatches_egsMatches = egs_merged_ID_tphotMatches[key_merged]\n",
    "egs_candels_ID_egsMatches = egs_candels_ID[key_candels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1498\n",
      "1498.0\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "i=1\n",
    "print(egs_merged_ID_tphotMatches_egsMatches[i])\n",
    "print(egs_candels_ID_egsMatches[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of egs_merged:\t 1606\n",
      "Number of egs_candels:\t 1606\n"
     ]
    }
   ],
   "source": [
    "print('Number of egs_merged:\\t',  len(egs_merged_ID_tphotMatches_egsMatches))\n",
    "print('Number of egs_candels:\\t', len(egs_candels_ID_egsMatches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1606\n",
      "1606\n",
      "1606\n"
     ]
    }
   ],
   "source": [
    "# helper indexing\n",
    "tphot_i         = idx_sep_unique\n",
    "egs_merged_i    = egs_merged_i_unique\n",
    "egs_candles_i   = key_candels\n",
    "\n",
    "# verify that all lengths match\n",
    "print(len(tphot_i))\n",
    "print(len(egs_merged_i))\n",
    "print(len(egs_candles_i))\n",
    "\n",
    "# save number of matches \n",
    "n_matches = len(tphot_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1606, 17)\n"
     ]
    }
   ],
   "source": [
    "# convert astropy table to pandas dataframe\n",
    "tphot_df = tphot_data.to_pandas()\n",
    "# get matched sources\n",
    "tphot_df_matched = tphot_df.iloc[tphot_i]\n",
    "print(tphot_df_matched.shape) # verify shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1606, 707)\n"
     ]
    }
   ],
   "source": [
    "# convert astropy table to pandas dataframe\n",
    "egs_merged_df = egs_merged_data.to_pandas()\n",
    "# get matched sources\n",
    "egs_merged_df_matched = egs_merged_df.iloc[egs_merged_i]\n",
    "print(egs_merged_df_matched.shape) # verify shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1606, 88)\n"
     ]
    }
   ],
   "source": [
    "# convert numpy array to pandas dataframe \n",
    "egs_candels_df = pd.DataFrame(egs_candels_data_bySrc, columns=egs_candels_cols)\n",
    "egs_candels_df['Source'] = egs_candels_df['Source'].astype(int) # correct data type\n",
    "# get matched sources\n",
    "egs_candels_df_matched = egs_candels_df.iloc[egs_candles_i]\n",
    "print(egs_candels_df_matched.shape) # verify shape\n",
    "\n",
    "# # TODO fix this?\n",
    "# # these temp columns did not read from file correctly...\n",
    "# print(egs_candels_data_byCol[55])\n",
    "# print(egs_candels_df['temp_only24'])\n",
    "# set dtype to object -- handle any data types. works now, but tricky to use values later... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1606, 812)\n"
     ]
    }
   ],
   "source": [
    "# concatenate tables horizontally\n",
    "full_table = pd.concat(\n",
    "        [tphot_df_matched.reset_index(drop=True), \n",
    "        egs_merged_df_matched.reset_index(drop=True), \n",
    "        egs_candels_df_matched.reset_index(drop=True)],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "print(full_table.shape) # verify shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print col names\n",
    "# for col in full_table.columns :\n",
    "#     print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output table to csv file \n",
    "full_table.to_csv('JWST_EGS_UniqueSources_AllColumns.csv', index=False)\n",
    "# NOTE columns that are not float datatype are 'nan'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "wantedCols = [\n",
    "    # ========================  tphot (all cols)\n",
    "    'field',                    \n",
    "    'ra', \n",
    "    'dec', \n",
    "    'f560w_uJy', \n",
    "    'f560w_uJy_err', \n",
    "    'f770w_uJy', \n",
    "    'f770w_uJy_err', \n",
    "    'f1000w_uJy', \n",
    "    'f1000w_uJy_err', \n",
    "    'f1280w_uJy', \n",
    "    'f1280w_uJy_err', \n",
    "    'f1500w_uJy', \n",
    "    'f1500w_uJy_err', \n",
    "    'f1800w_uJy', \n",
    "    'f1800w_uJy_err', \n",
    "    'f2100w_uJy', \n",
    "    'f2100w_uJy_err',\n",
    "    # ========================  egs_merged\n",
    "    'ID', \n",
    "    'z_best',\n",
    "    'zbest',                                            # ??? WHY TWO Z BEST?\n",
    "    'RA',\n",
    "    'DEC',\n",
    "    'IRAC_CH1_FLUX',\n",
    "    'IRAC_CH1_FLUXERR',\n",
    "    'IRAC_CH2_FLUX',\n",
    "    'IRAC_CH2_FLUXERR',\n",
    "    'IRAC_CH3_FLUX',\n",
    "    'IRAC_CH3_FLUXERR',\n",
    "    'IRAC_CH4_FLUX',\n",
    "    'IRAC_CH4_FLUXERR',\n",
    "    'IRAC_CH3_V08_FLUX',\n",
    "    'IRAC_CH3_V08_FLUXERR', \n",
    "    # ========================  egs_candles\n",
    "    'Source',                   \n",
    "    'z',                                                # ??? more z?\n",
    "    'l_IRAC_58',    # IRAC CH 3                         # ??? what is l and f?\n",
    "    'f_IRAC_58',\n",
    "    'l_IRAC_80',    # IRAC CH 4\n",
    "    'f_IRAC_80',\n",
    "    'l_MIPS24',\n",
    "    'f_MIPS24',\n",
    "    'l_MIPS70',\n",
    "    'f_MIPS70',\n",
    "    'l_PACS_100',\n",
    "    'f_PACS_100',\n",
    "    'l_PACS_160',\n",
    "    'f_PACS_160',\n",
    "    'l_SPIRE_250',\n",
    "    'f_SPIRE_250',\n",
    "    'l_SPIRE_350',\n",
    "    'f_SPIRE_350',\n",
    "    'l_SPIRE_500',\n",
    "    'f_SPIRE_500'\n",
    "]\n",
    "# any more?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make table of only wanted columns \n",
    "reduced_table = full_table[wantedCols]\n",
    "\n",
    "# print cols (test)\n",
    "# print(reduced_table.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output table to csv file \n",
    "reduced_table.to_csv('JWST_EGS_UniqueSources_ReducedColumns.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('py3env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9087279304570de5a36832bd291691fdf2a46b942e9196516ec718f5eedeadfe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
